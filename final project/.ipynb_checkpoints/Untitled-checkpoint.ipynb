{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from skimage import io, color\n",
    "import cv2\n",
    "import sklearn\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "from skimage import exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pickle\n",
    "import imageio\n",
    "import glob\n",
    "\n",
    "from sequence_classifiers import CNNSequenceClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First change the name of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the name of the images and change the resolution to 256 * 256\n",
    "#but don't strech the images, remain the original height to width ratio\n",
    "#if the image is smaller than 256 * 256, enlarge the image so that the smallest edge is 256 pxs\n",
    "#if the image is larger than 256 * 256 in both edge, resize the image so that the smallest edge is 256 px\n",
    "#and then, cut the image so that we want the middle 256 * 256 pixels\n",
    "\n",
    "def resize_and_cut(name, result_name):\n",
    "    im = Image.open(name)\n",
    "    mywidth = 192\n",
    "    myheight = 192\n",
    "    imagewidth = (im.size[0])\n",
    "    imageheight = (im.size[1])\n",
    "    if (imagewidth < imageheight):\n",
    "        wpercent = (mywidth/float(imagewidth))\n",
    "        hsize = int((float(imageheight)*float(wpercent)))\n",
    "        im = im.resize((mywidth,hsize), PIL.Image.ANTIALIAS)\n",
    "        difference = (hsize - myheight) / 2\n",
    "        area = (0, difference, mywidth, hsize - difference)\n",
    "        cropped_img = im.crop(area)\n",
    "        cropped_img.save(result_name)\n",
    "    else:\n",
    "        hpercent = (myheight/float(imageheight))\n",
    "        wsize = int((float(imagewidth)*float(hpercent)))\n",
    "        im = im.resize((wsize,myheight), PIL.Image.ANTIALIAS)\n",
    "        difference = (wsize - mywidth) /2\n",
    "        area = (difference, 0, wsize - difference, myheight)\n",
    "        cropped_img = im.crop(area)\n",
    "        cropped_img.save(result_name)\n",
    "    os.remove(name)\n",
    "        \n",
    "def change_all_size():\n",
    "    for folder_name in glob.glob('images/*'):\n",
    "        count = 1\n",
    "        name_list = []\n",
    "        for name in glob.glob('%s/*' %folder_name):\n",
    "            if (name.endswith(\".jpg\")):\n",
    "                name_list.append([name, '%s/%s.jpg' %(folder_name,count)])\n",
    "                count +=1\n",
    "        for name in name_list:\n",
    "            resize_and_cut(name[0], name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change_all_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the initial thoughts: something that is within the spirit of A3.\n",
    "## But it turns out that this way doesn't perform well. After some researchs, I think there shall be other algorithms first to separate the desired image from the complex backgrounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put images of the same bird categories into a numpy array\n",
    "# Put all images into a dictionary\n",
    "def put_in_numpy_array():\n",
    "    dummy_value = 0\n",
    "    images = []\n",
    "    for folder_name in glob.glob('images/*'):\n",
    "        for name in glob.glob('%s/*' %folder_name):\n",
    "            img = io.imread(name)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images\n",
    "\n",
    "def put_in_numpy_array2():\n",
    "    dummy_value = 0\n",
    "    images = []\n",
    "    for folder_name in glob.glob('images2/*'):\n",
    "        for name in glob.glob('%s/*' %folder_name):\n",
    "            img = io.imread(name)\n",
    "            images.append(img)\n",
    "            \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Y value of all images, concatenated\n",
    "def get_all_Y():\n",
    "    dummy_value = 0\n",
    "    for folder_name in glob.glob('images/*'):\n",
    "        value = (folder_name[7:10])\n",
    "        length = (len(glob.glob('%s/*' %folder_name)))\n",
    "        if dummy_value == 0:\n",
    "            all_Y = np.full((1, int('%s' %length)), value)[0]\n",
    "            dummy_value = 1\n",
    "        else:\n",
    "            new_input = np.full((1, int('%s' %length)), value)[0]\n",
    "            all_Y = np.concatenate((all_Y, new_input), axis=0)\n",
    "    return all_Y\n",
    "\n",
    "def get_all_Y2():\n",
    "    dummy_value = 0\n",
    "    for folder_name in glob.glob('images2/*'):\n",
    "        value = (folder_name[8:11])\n",
    "        length = (len(glob.glob('%s/*' %folder_name)))\n",
    "        if dummy_value == 0:\n",
    "            all_Y = np.full((1, int('%s' %length)), value)[0]\n",
    "            dummy_value = 1\n",
    "        else:\n",
    "            new_input = np.full((1, int('%s' %length)), value)[0]\n",
    "            all_Y = np.concatenate((all_Y, new_input), axis=0)\n",
    "    return all_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(all_X, all_Y):\n",
    "    print(all_X.shape)\n",
    "    print(all_Y.shape)\n",
    "    All_Flat_X = np.array([image.flatten() for image in all_X])\n",
    "    print(All_Flat_X.shape)\n",
    "    return All_Flat_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test(All_Flat_X, all_Y):\n",
    "    # This only splits a numpy array into two random sub-arrays, \n",
    "    # but if you're clever you can also use it to get a validation set with just one more line of code\n",
    "\n",
    "    # Your code goes here\n",
    "    Train_X, Test_X, Train_y, Test_y = sklearn.model_selection.train_test_split(All_Flat_X, all_Y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Print out the following\n",
    "    print (len(Train_X), len(Train_y), len(Test_X), len(Test_y))\n",
    "    print (Train_X[0])\n",
    "    \n",
    "    return (Train_X, Test_X, Train_y, Test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(Train_X, Train_y, Test_X, Test_y):\n",
    "    model = Pipeline([\n",
    "        ('MultinomialNB',MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    model.fit(Train_X,Train_y)\n",
    "    predict_accuracy = sum(cross_val_score(model, Test_X, Test_y, cv=3))/3\n",
    "    predict = model.predict(Test_X)\n",
    "    predict_f1_socre = f1_score(Test_y, predict, average='weighted')\n",
    "\n",
    "    predict_matrix = confusion_matrix(Test_y, predict)\n",
    "    print(predict_accuracy)\n",
    "    print(predict_f1_socre)\n",
    "    print(predict_matrix)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_model(model, name):\n",
    "    f = open(name + '.pckl', 'wb')\n",
    "    pickle.dump(model, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_model(name):\n",
    "    f = open(name + '.pckl', 'rb')\n",
    "    test = pickle.load(f)\n",
    "    f.close()\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So initially the model ends here. But the accuracy is really low.\n",
    "## So I decide to check some other ways to increase the accuracy. After some research, I think I shall first make the image segmentation. There are multiple algorithms, but I need to find some of the ones that are useful in this situation.\n",
    "### This is more like a trying and trying until the segmentation is mostly pleasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(name):\n",
    "    windowName = \"Edges\"\n",
    "    pictureRaw = cv2.imread(name)\n",
    "    \n",
    "    fig=plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(2,4,1)\n",
    "    plt.imshow(pictureRaw[:,:,::-1])\n",
    "    plt.title('original image')\n",
    "\n",
    "    ## set to gray\n",
    "    pictureGray = cv2.cvtColor(pictureRaw,  cv2.COLOR_BGR2GRAY)\n",
    "    ## blur\n",
    "    pictureGaussian = cv2.GaussianBlur(pictureGray, (21,21), 0)\n",
    "    ## canny edge detector - you must specify threshold values\n",
    "    pictureCanny = cv2.Canny(pictureGaussian, 50, 100)\n",
    "    ## perform a series of erosions + dilations to remove any small regions of noise\n",
    "    pictureDilate = cv2.dilate(pictureCanny, None, iterations= 50)\n",
    "    pictureErode = cv2.erode(pictureDilate, None, iterations=5)\n",
    "\n",
    "    #the erosion + dilation\n",
    "    plt.subplot(2,4,2)\n",
    "    plt.imshow(pictureErode)\n",
    "    plt.title('erosions + dilations')\n",
    "\n",
    "\n",
    "\n",
    "    #Otsu thresholding\n",
    "    Otsu = pictureRaw\n",
    "    Otsugray = cv2.cvtColor(Otsu,cv2.COLOR_BGR2GRAY)\n",
    "    Otsuret, Otsuthresh = cv2.threshold(Otsugray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    plt.subplot(2,4,3)\n",
    "    plt.imshow(Otsuthresh)\n",
    "    plt.title('Otsu thresholding')\n",
    "\n",
    "\n",
    "    #combined\n",
    "    combined = Otsuthresh + pictureErode\n",
    "    plt.subplot(2,4,4)\n",
    "    plt.imshow(combined)\n",
    "    plt.title('combined')\n",
    "\n",
    "    #masked result\n",
    "    imask = combined > 0\n",
    "    canvas = np.full_like(pictureRaw, np.array([0,0,0]), dtype=np.uint8)\n",
    "    canvas[imask] = pictureRaw[imask]\n",
    "    plt.subplot(2,4,5)\n",
    "    plt.imshow(canvas[:,:,::-1])\n",
    "    plt.title('result of combined mask')\n",
    "\n",
    "\n",
    "    #grab cut\n",
    "    grabimg = pictureRaw\n",
    "    grabmask = np.zeros(grabimg.shape[:2],np.uint8)\n",
    "    grabbgdModel = np.zeros((1,65),np.float64)\n",
    "    grabfgdModel = np.zeros((1,65),np.float64)\n",
    "    grabrect = (50,50,1000,1000)\n",
    "    cv2.grabCut(grabimg,grabmask,grabrect,grabbgdModel,grabfgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "    grabmask2 = np.where((grabmask==2)|(grabmask==0),0,1).astype('uint8')\n",
    "    grabimg = grabimg*grabmask2[:,:,np.newaxis]\n",
    "    fig.add_subplot(2, 4, 6)\n",
    "    plt.imshow(grabimg[:,:,::-1])\n",
    "    plt.title('grab Cut')\n",
    "\n",
    "\n",
    "    '''\n",
    "    #adaptiveThreshold\n",
    "    adaptiveimg = cv2.imread(name,0)\n",
    "    adaptiveimg = cv2.medianBlur(adaptiveimg,5)\n",
    "    adaptiveret,adaptiveth1 = cv2.threshold(adaptiveimg,127,255,cv2.THRESH_BINARY)\n",
    "    adaptiveth2 = cv2.adaptiveThreshold(adaptiveimg,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    adaptiveth3 = cv2.adaptiveThreshold(adaptiveimg,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "    fig.add_subplot(2, 4, 6)\n",
    "    plt.imshow(adaptiveth3[:,:,::-1])\n",
    "    plt.title('adaptiveThreshold')\n",
    "    '''\n",
    "\n",
    "    #combined the Otsu and grab Cut\n",
    "    imask2 = Otsuthresh > 0\n",
    "    canvas2 = np.full_like(grabimg, np.array([0,0,0]), dtype=np.uint8)\n",
    "    canvas2[imask2] = grabimg[imask2]\n",
    "    plt.subplot(2,4,7)\n",
    "    plt.imshow(canvas2[:,:,::-1])\n",
    "    plt.title('Otsu and Grab Combined')\n",
    "\n",
    "    #combined of all things\n",
    "    #first filter the image by applying erosions + dilations and Otsu\n",
    "    #then filter the resulting image by applying grab Cut\n",
    "    combinedImage = canvas\n",
    "    combinedImage = combinedImage*grabmask2[:,:,np.newaxis]\n",
    "    fig.add_subplot(2, 4, 8)\n",
    "    plt.imshow(combinedImage[:,:,::-1])\n",
    "    plt.title('dilation + Otsu -> grab')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample('1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample('2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample('3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample('4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample('5.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this point, I decide to use the combined mask of dilation + erotion and the Otsu thresholding. Then it applied the mask of the grab Cut.\n",
    "### Dilation + erotion can first get the \"shape\" of the image. Otsu threasholding has very pleasing result if human effort is involved (like it has a really good shape sometimes), but it omits a lot of important ares. The dilation and erotion method dependes on the threashold I input. I would rather input a larger value, since I would prefer to contain more \"useless\" area rather than losting \"important area\".\n",
    "### The result of this dilation + erotion and Otsu mask is \"huge\", as it contains way more useless areas than it should. So the grab cut was like a better smaller and more accurate mask applied on the image. As we can see in the result, most of the job is done by the grab cut. But the former mask sometimes can remove areas that grab cut along cannot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_image(name):\n",
    "    windowName = \"Edges\"\n",
    "    pictureRaw = cv2.imread(name)\n",
    "    \n",
    "    #the erosion + dilation\n",
    "    pictureGray = cv2.cvtColor(pictureRaw,  cv2.COLOR_BGR2GRAY)\n",
    "    pictureGaussian = cv2.GaussianBlur(pictureGray, (21,21), 0)\n",
    "    pictureCanny = cv2.Canny(pictureGaussian, 50, 100)\n",
    "    pictureDilate = cv2.dilate(pictureCanny, None, iterations= 50)\n",
    "    pictureErode = cv2.erode(pictureDilate, None, iterations=5)\n",
    "\n",
    "    #Otsu thresholding\n",
    "    Otsu = pictureRaw\n",
    "    Otsugray = cv2.cvtColor(Otsu,cv2.COLOR_BGR2GRAY)\n",
    "    Otsuret, Otsuthresh = cv2.threshold(Otsugray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "    #combined\n",
    "    combined = Otsuthresh + pictureErode\n",
    "\n",
    "    #masked result\n",
    "    imask = combined > 0\n",
    "    canvas = np.full_like(pictureRaw, np.array([0,0,0]), dtype=np.uint8)\n",
    "    canvas[imask] = pictureRaw[imask]\n",
    "\n",
    "\n",
    "    #grab cut\n",
    "    grabimg = pictureRaw\n",
    "    grabmask = np.zeros(grabimg.shape[:2],np.uint8)\n",
    "    grabbgdModel = np.zeros((1,65),np.float64)\n",
    "    grabfgdModel = np.zeros((1,65),np.float64)\n",
    "    grabrect = (50,50,1000,1000)\n",
    "    try:\n",
    "        cv2.grabCut(grabimg,grabmask,grabrect,grabbgdModel,grabfgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "    except:\n",
    "        print(name)\n",
    "    grabmask2 = np.where((grabmask==2)|(grabmask==0),0,1).astype('uint8')\n",
    "    grabimg = grabimg*grabmask2[:,:,np.newaxis]\n",
    "\n",
    "    #combined of all things\n",
    "    #first filter the image by applying erosions + dilations and Otsu\n",
    "    #then filter the resulting image by applying grab Cut\n",
    "    combinedImage = (canvas*grabmask2[:,:,np.newaxis])[:,:,::-1]\n",
    "    imageio.imsave(name, combinedImage)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_backgrounds():\n",
    "    for folder_name in glob.glob('images/*'):\n",
    "        print('***' + folder_name + '***')\n",
    "        name_list = []\n",
    "        for name in glob.glob('%s/*' %folder_name):\n",
    "            if (name.endswith(\".jpg\")):\n",
    "                name_list.append(name)\n",
    "        for name in name_list:\n",
    "            change_image(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black():\n",
    "    for folder_name in glob.glob('images/*'):\n",
    "        name_list = []\n",
    "        for name in glob.glob('%s/*' %folder_name):\n",
    "            if (name.endswith(\".jpg\")):\n",
    "                name_list.append(name)\n",
    "        for name in name_list:\n",
    "            if ((sum(sum(sum(np.int32(cv2.imread(name)))))) < 10000):\n",
    "                os.remove(name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grey_image():\n",
    "    for folder_name in glob.glob('images/*'):\n",
    "        print('***' + folder_name + '***')\n",
    "        name_list = []\n",
    "        for name in glob.glob('%s/*' %folder_name):\n",
    "            if (name.endswith(\".jpg\")):\n",
    "                name_list.append(name)\n",
    "        for name in name_list:\n",
    "            im = Image.open(name).convert('LA')\n",
    "            rgb_im = im.convert('RGB')\n",
    "            rgb_im.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smaller_sample(inputnumber):\n",
    "    for folder_name in glob.glob('images/*'):\n",
    "        name_list = []\n",
    "        for name in glob.glob('%s/*' %folder_name):\n",
    "            if (name.endswith(\".jpg\")):\n",
    "                name_list.append(name)\n",
    "        for name in name_list:\n",
    "            number = int((name[(len(folder_name)+1):-4]))\n",
    "            if number > inputnumber:\n",
    "                os.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_all_images_final():\n",
    "    change_all_size()\n",
    "    smaller_sample(20)\n",
    "    remove_all_backgrounds()\n",
    "    remove_black()\n",
    "#change_all_images_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def final_model_1():\n",
    "    all_X = put_in_numpy_array()\n",
    "    all_X = np.array(all_X)\n",
    "    All_Flat_X = np.array([image.flatten() for image in all_X])\n",
    "    all_Y = get_all_Y()\n",
    "    sanity_check(all_X, all_Y)\n",
    "    (Train_X, Test_X, Train_y, Test_y) = split_train_and_test(All_Flat_X, all_Y)\n",
    "    model = fit_model(Train_X, Train_y, Test_X, Test_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model_2():\n",
    "    all_X = put_in_numpy_array2()\n",
    "    all_X = np.array(all_X)\n",
    "    All_Flat_X = np.array([image.flatten() for image in all_X])\n",
    "    all_Y = get_all_Y2()\n",
    "    sanity_check(all_X, all_Y)\n",
    "    (Train_X, Test_X, Train_y, Test_y) = split_train_and_test(All_Flat_X, all_Y)\n",
    "    model = fit_model(Train_X, Train_y, Test_X, Test_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3630, 192, 192, 3)\n",
      "(3630,)\n",
      "(3630, 110592)\n",
      "2904 2904 726 726\n",
      "[ 0  0  0 ... 77 83 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobiichi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/Tobiichi/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Tobiichi/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016920016252088856\n",
      "0.013555507853028514\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "(4000, 192, 192, 3)\n",
      "(4000,)\n",
      "(4000, 110592)\n",
      "3200 3200 800 800\n",
      "[ 64 103  59 ...  96  83  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobiichi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02541056777791964\n",
      "0.027159661732746098\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobiichi/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model1 = final_model_1()\n",
    "model2 = final_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test(name):\n",
    "    new_image = (cv2.imread('images/' + name))\n",
    "    test = [((np.array(new_image)).flatten())]\n",
    "    test = np.array(test)\n",
    "    print('result of 1')\n",
    "    try:\n",
    "        print(model1.predict(test))\n",
    "    except:\n",
    "        print('not this image')\n",
    "    new_image = (cv2.imread('images2/' + name))\n",
    "    test = [((np.array(new_image)).flatten())]\n",
    "    test = np.array(test)\n",
    "    print('result of 2')\n",
    "    print(model2.predict(test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_test():\n",
    "    for i in range(21):\n",
    "        if (i != 0):\n",
    "            print(i)\n",
    "            random_test('001.Black_footed_Albatross/%s.jpg' %i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_model(model1, 'model1')\n",
    "store_model(model2, 'model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = open_model('model1')\n",
    "test_2 = open_model('model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['145'], dtype='<U3')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.predict(np.array([((np.array((cv2.imread('images/001.Black_footed_Albatross/2.jpg')))).flatten())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['145'], dtype='<U3')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(np.array([((np.array((cv2.imread('images/001.Black_footed_Albatross/2.jpg')))).flatten())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_all_size_2():\n",
    "    for folder_name in glob.glob('original_images/*'):\n",
    "        count = 1\n",
    "        name_list = []\n",
    "        for name in glob.glob('%s/*' %folder_name):\n",
    "            if (name.endswith(\".jpg\")):\n",
    "                name_list.append([name, '%s/%s.jpg' %(folder_name,count)])\n",
    "                count +=1\n",
    "                \n",
    "        for name in name_list:\n",
    "            im = Image.open(name[0])\n",
    "            im.save(name[1])\n",
    "            os.remove(name[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
